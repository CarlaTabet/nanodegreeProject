{
 "cells": [
  {
   "cell_type": "raw",
   "id": "86542fb5-8033-4cea-9957-8534f1581294",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "- PEFT technique: I chose the LoRa technique. This technique allows large pre-trained models to be fine tuned by reducing the number of parameters.\n",
    "- Model: I chose the distilbert-base-uncased model, as it is smaller than gpt-2\n",
    "- Evaluation approach: The evaluation approach included calculating the accuracy metric using the Hugging Face Trainer. The accuracy metric compared the correctness of the models predictions with the true labels.\n",
    "- Fine-tuning dataset: I selected the ag_news dataset. It is a relatively small dataset, and was therefore a good choice for demonstrating the effectiveness of fine-tuning techniques\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2f19118-4efd-4908-9c2b-fb483d852147",
   "metadata": {},
   "source": [
    "Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cc821b30-d8dc-4ce3-97f5-c14bc2d9057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./.venv/lib/python3.9/site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./.venv/lib/python3.9/site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.9/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.9/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.venv/lib/python3.9/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.9/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests->transformers) (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./.venv/lib/python3.9/site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.9/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.9/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.venv/lib/python3.9/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.9/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.9/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in ./.venv/lib/python3.9/site-packages (from datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.9/site-packages (from datasets) (3.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in ./.venv/lib/python3.9/site-packages (from datasets) (0.24.5)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.9/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->datasets) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.9/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in ./.venv/lib/python3.9/site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.9/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.9/site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.9/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in ./.venv/lib/python3.9/site-packages (from peft) (2.2.2)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.9/site-packages (from peft) (4.43.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.9/site-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in ./.venv/lib/python3.9/site-packages (from peft) (0.33.0)\n",
      "Requirement already satisfied: safetensors in ./.venv/lib/python3.9/site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in ./.venv/lib/python3.9/site-packages (from peft) (0.24.5)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.9/site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.9/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.9/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.9/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.9/site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.9/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.9/site-packages (from transformers->peft) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.venv/lib/python3.9/site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.9/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.9/site-packages (8.1.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.9/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.9/site-packages (from ipywidgets) (8.18.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.9/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in ./.venv/lib/python3.9/site-packages (from ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in ./.venv/lib/python3.9/site-packages (from ipywidgets) (3.0.11)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.venv/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.9/site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install numpy\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install peft\n",
    "!pip install ipywidgets --upgrade\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fe1c17d0-6865-4d0f-950d-dd6018265cbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, EvalPrediction, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, AutoPeftModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "raw",
   "id": "286de2da-eb5c-48a7-a1fa-83072fe8da41",
   "metadata": {},
   "source": [
    "Loading and Evaluating a Foundation Model\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dc9ba145-1592-469f-a6ce-6232d78fed22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels=4)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# load the dataset\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "\n",
    "# From class example\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "# tokenize the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88e43bb4-131e-4b95-8729-b2658f3f8723",
   "metadata": {},
   "source": [
    "Made a compute_metrics to evaluate performence (used class notes to help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c5a18d98-ecd0-4318-9227-71911633b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='macro', zero_division=1)\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a2cba2d8-6f0c-4cd1-96aa-8e112c115181",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    ")\n",
    "\n",
    "# made smaller subset for sake of running in time\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"].shuffle().select([i for i in range(100)]),\n",
    "    eval_dataset=tokenized_datasets[\"test\"].shuffle().select([i for i in range(100)]),\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8ec021e1-c190-4b46-b07f-d1e4edfcb5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial results: {'eval_loss': 5.065890789031982, 'eval_model_preparation_time': 0.002, 'eval_accuracy': 0.21, 'eval_f1': 0.09972041006523766, 'eval_precision': 0.5827228327228327, 'eval_recall': 0.20892857142857144, 'eval_runtime': 3.2466, 'eval_samples_per_second': 30.802, 'eval_steps_per_second': 4.004}\n"
     ]
    }
   ],
   "source": [
    "# evaluate initial model without training\n",
    "initial_results = trainer.evaluate()\n",
    "print(f\"Initial results: {initial_results}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac22af2c-1f0c-455b-9e31-47bca1964a19",
   "metadata": {},
   "source": [
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "58bbfc77-5012-44d0-9044-c4cedbc9053a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,064,384 || all params: 126,507,264 || trainable%: 1.6318\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.924701</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.089345</td>\n",
       "      <td>0.566220</td>\n",
       "      <td>0.178929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LoRA configuration\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"attn.c_attn\", \"mlp.c_fc\", \"mlp.c_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    fan_in_fan_out = True\n",
    ")\n",
    "\n",
    "# create a PEFT model\n",
    "lora_model = get_peft_model(model, config)\n",
    "lora_model.print_trainable_parameters()\n",
    "\n",
    "# train the model now\n",
    "trainer.model = lora_model\n",
    "trainer.train()\n",
    "lora_model.save_pretrained(\"peft-lora\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6f12045-2d49-4c2d-b62d-0e0768d10a29",
   "metadata": {},
   "source": [
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f5ebe560-1aed-4385-b8dc-4491296fdb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned results: {'eval_loss': 1.9648971557617188, 'eval_model_preparation_time': 0.0043, 'eval_accuracy': 0.22, 'eval_f1': 0.09016393442622951, 'eval_precision': 0.8049999999999999, 'eval_recall': 0.25, 'eval_runtime': 3.7354, 'eval_samples_per_second': 26.771, 'eval_steps_per_second': 3.48}\n",
      "Accuracy Improvement: 0.010000000000000009\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "lora_model = AutoPeftModelForSequenceClassification.from_pretrained(\"peft-lora\")\n",
    "lora_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_datasets[\"test\"].shuffle().select([i for i in range(100)]),\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "\n",
    "# now evaluate trained model\n",
    "trainer.model = lora_model\n",
    "fine_tuned_result = trainer.evaluate()\n",
    "print(f\"Fine-tuned results: {fine_tuned_result}\")\n",
    "\n",
    "# use accuracy to evaluate improvement\n",
    "initial_accuracy = initial_results[\"eval_accuracy\"]\n",
    "fine_tuned_accuracy = fine_tuned_result[\"eval_accuracy\"]\n",
    "change = fine_tuned_accuracy - initial_accuracy\n",
    "print(f\"Accuracy Improvement: {change}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
